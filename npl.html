<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>NLP Master | Complete Learning Platform</title>

<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;800&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>

<style>
:root{
  --bg:#0f1420;
  --glass:rgba(255,255,255,0.06);
  --card:#151b2d;
  --nlp-blue:#4a9eff;
  --nlp-green:#51cf66;
  --nlp-purple:#9f7aea;
  --nlp-pink:#ff4d8d;
  --nlp-orange:#ffa94d;
  --text:#e5e7eb;
  --success:#00ff9d;
  --warning:#ffcc00;
  --danger:#ff4757;
  --info:#4d8af0;
}

*{margin:0;padding:0;box-sizing:border-box;font-family:Poppins,sans-serif}

body{
  background:
    radial-gradient(circle at 10% 20%, rgba(74,158,255,.15), transparent 40%),
    radial-gradient(circle at 90% 30%, rgba(81,207,102,.12), transparent 40%),
    radial-gradient(circle at 40% 80%, rgba(159,122,234,.08), transparent 40%),
    linear-gradient(180deg,#0f1420,var(--bg));
  color:var(--text);
  min-height: 100vh;
}

/* NAV */
nav{
  position:sticky;
  top:0;
  z-index:10;
  padding:18px 50px;
  background:rgba(15,20,31,.95);
  backdrop-filter:blur(14px);
  border-bottom:1px solid rgba(255,255,255,.08);
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.logo{
  font-size:1.6rem;
  font-weight:800;
  background:linear-gradient(90deg,var(--nlp-blue),var(--nlp-green));
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
}

.nav-links {
  display: flex;
  gap: 15px;
}

.nav-links a {
  color: var(--text);
  text-decoration: none;
  font-weight: 500;
  font-size: 0.85rem;
  transition: all 0.3s;
  padding: 8px 15px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  gap: 8px;
}

.nav-links a:hover {
  background: rgba(255,255,255,0.08);
  color: var(--nlp-blue);
}

.nav-links a.active {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  color: var(--bg);
}

/* STUDY MODES */
.study-modes {
  display: flex;
  justify-content: center;
  gap: 15px;
  margin: 40px 0;
  flex-wrap: wrap;
  padding: 0 20px;
}

.mode-btn {
  padding: 15px 25px;
  border-radius: 15px;
  background: rgba(255,255,255,0.05);
  border: 2px solid rgba(255,255,255,0.1);
  color: var(--text);
  font-weight: 600;
  cursor: pointer;
  transition: all 0.3s;
  display: flex;
  align-items: center;
  gap: 10px;
  min-width: 180px;
  justify-content: center;
}

.mode-btn:hover {
  transform: translateY(-5px);
  border-color: var(--nlp-blue);
  box-shadow: 0 10px 30px rgba(74,158,255,0.2);
}

.mode-btn.active {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  color: var(--bg);
  border-color: transparent;
  box-shadow: 0 10px 30px rgba(74,158,255,0.4);
}

.mode-icon {
  font-size: 1.2rem;
}

/* STUDY SECTIONS */
.study-section {
  display: none;
  animation: fadeIn 0.5s ease;
  padding: 0 50px;
  max-width: 1400px;
  margin: 0 auto;
}

.study-section.active {
  display: block;
}

@keyframes fadeIn {
  from { opacity: 0; transform: translateY(20px); }
  to { opacity: 1; transform: translateY(0); }
}

.section-header {
  text-align: center;
  margin-bottom: 40px;
}

.section-header h2 {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 2.5rem;
  margin-bottom: 10px;
}

.section-icon {
  font-size: 3rem;
  color: var(--nlp-blue);
  margin-bottom: 15px;
}

/* FUNDAMENTALS */
.fundamentals-container {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
  gap: 30px;
  margin-top: 30px;
}

.concept-card {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 30px;
  border: 1px solid rgba(255,255,255,0.12);
  transition: all 0.3s;
  position: relative;
  overflow: hidden;
}

.concept-card:hover {
  transform: translateY(-10px);
  border-color: var(--nlp-blue);
  box-shadow: 0 15px 40px rgba(74,158,255,0.2);
}

.concept-card h3 {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 1.4rem;
  margin-bottom: 15px;
  padding-bottom: 10px;
  border-bottom: 1px solid rgba(255,255,255,0.1);
}

.concept-card p {
  line-height: 1.7;
  margin-bottom: 20px;
  opacity: 0.9;
}

.concept-formula {
  background: rgba(0,0,0,0.3);
  border-radius: 10px;
  padding: 15px;
  margin: 15px 0;
  border-left: 3px solid var(--nlp-blue);
  font-family: 'Courier New', monospace;
  font-size: 0.9rem;
}

.concept-list {
  list-style: none;
  padding: 0;
  margin-top: 20px;
}

.concept-list li {
  padding: 8px 0;
  border-bottom: 1px solid rgba(255,255,255,0.05);
  display: flex;
  align-items: center;
  gap: 10px;
}

.concept-list li:last-child {
  border-bottom: none;
}

.concept-badge {
  position: absolute;
  top: 15px;
  right: 15px;
  padding: 5px 15px;
  border-radius: 20px;
  font-size: 0.8rem;
  font-weight: 600;
  background: rgba(74,158,255,0.15);
  color: var(--nlp-blue);
}

/* TEXT PROCESSING TOOLS */
.text-processing {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 30px;
  margin-top: 30px;
  border: 1px solid rgba(255,255,255,0.12);
}

.tools-container {
  display: grid;
  grid-template-columns: 300px 1fr;
  gap: 30px;
  margin: 30px 0;
}

@media (max-width: 1024px) {
  .tools-container {
    grid-template-columns: 1fr;
  }
}

.tools-sidebar {
  background: rgba(255,255,255,0.05);
  border-radius: 15px;
  padding: 20px;
}

.tool-panel {
  background: rgba(0,0,0,0.3);
  border-radius: 15px;
  padding: 20px;
  border: 1px solid rgba(255,255,255,0.1);
}

.tool-group {
  margin-bottom: 25px;
}

.tool-group h4 {
  color: var(--nlp-blue);
  margin-bottom: 15px;
  font-size: 1.1rem;
}

.tool-btn {
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(255,255,255,0.1);
  color: var(--text);
  padding: 10px 15px;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.3s;
  display: flex;
  align-items: center;
  gap: 10px;
  width: 100%;
  margin-bottom: 10px;
}

.tool-btn:hover {
  background: rgba(74,158,255,0.1);
  border-color: var(--nlp-blue);
}

.tool-btn.active {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  color: var(--bg);
  border-color: transparent;
}

.text-input-area {
  width: 100%;
  min-height: 200px;
  background: rgba(0,0,0,0.5);
  border: 1px solid rgba(255,255,255,0.1);
  border-radius: 10px;
  padding: 15px;
  color: var(--text);
  font-family: 'Courier New', monospace;
  font-size: 1rem;
  resize: vertical;
  margin-bottom: 20px;
}

.process-btn {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  color: var(--bg);
  border: none;
  padding: 12px 30px;
  border-radius: 10px;
  cursor: pointer;
  font-weight: 600;
  transition: all 0.3s;
  display: flex;
  align-items: center;
  gap: 10px;
  width: 100%;
  justify-content: center;
}

.process-btn:hover {
  transform: translateY(-3px);
  box-shadow: 0 10px 30px rgba(74,158,255,0.4);
}

.results-panel {
  background: rgba(0,0,0,0.3);
  border-radius: 15px;
  padding: 20px;
  border: 1px solid rgba(81,207,102,0.2);
  min-height: 300px;
  overflow-y: auto;
}

.result-item {
  margin-bottom: 15px;
  padding-bottom: 15px;
  border-bottom: 1px solid rgba(255,255,255,0.1);
}

.result-item:last-child {
  border-bottom: none;
}

/* MODEL PLAYGROUND */
.model-playground {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 30px;
  margin-top: 30px;
  border: 1px solid rgba(255,255,255,0.12);
}

.model-container {
  display: grid;
  grid-template-columns: 300px 1fr 300px;
  gap: 30px;
  margin-top: 30px;
}

@media (max-width: 1200px) {
  .model-container {
    grid-template-columns: 1fr;
  }
}

.model-controls {
  background: rgba(255,255,255,0.05);
  border-radius: 15px;
  padding: 20px;
}

.model-canvas {
  background: rgba(0,0,0,0.3);
  border-radius: 15px;
  padding: 20px;
  border: 1px solid rgba(255,255,255,0.1);
  min-height: 400px;
  position: relative;
}

.model-results {
  background: rgba(255,255,255,0.05);
  border-radius: 15px;
  padding: 20px;
  overflow-y: auto;
  max-height: 400px;
}

/* QUESTION BANK */
.question-filters {
  display: flex;
  gap: 15px;
  margin: 30px 0;
  flex-wrap: wrap;
}

.filter-btn {
  padding: 10px 25px;
  border-radius: 10px;
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(255,255,255,0.1);
  color: var(--text);
  cursor: pointer;
  transition: all 0.3s;
}

.filter-btn:hover {
  background: rgba(74,158,255,0.1);
  border-color: var(--nlp-blue);
}

.filter-btn.active {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  color: var(--bg);
  border-color: transparent;
}

.question-bank {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
  gap: 25px;
  margin-top: 30px;
}

.question-item {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 25px;
  border: 1px solid rgba(255,255,255,0.12);
  transition: all 0.3s;
}

.question-item:hover {
  transform: translateY(-5px);
  border-color: var(--nlp-blue);
  box-shadow: 0 15px 40px rgba(74,158,255,0.2);
}

.question-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 15px;
}

.question-header h4 {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 1.1rem;
}

.question-meta {
  display: flex;
  gap: 10px;
  font-size: 0.8rem;
  opacity: 0.8;
}

.question-text {
  margin-bottom: 20px;
  line-height: 1.6;
}

.question-options {
  margin: 15px 0;
}

.option {
  padding: 10px;
  margin: 8px 0;
  background: rgba(255,255,255,0.05);
  border-radius: 8px;
  border: 1px solid rgba(255,255,255,0.1);
  cursor: pointer;
  transition: all 0.2s;
}

.option:hover {
  background: rgba(74,158,255,0.1);
}

.option.correct {
  background: rgba(81,207,102,0.15);
  border-color: var(--nlp-green);
}

.option.incorrect {
  background: rgba(255,71,87,0.15);
  border-color: var(--danger);
}

.question-answer {
  background: rgba(81,207,102,0.05);
  border-radius: 10px;
  padding: 15px;
  margin-top: 15px;
  border-left: 3px solid var(--nlp-green);
  display: none;
}

.question-explanation {
  font-size: 0.9rem;
  color: var(--text);
  opacity: 0.9;
  margin-top: 10px;
  font-style: italic;
}

.show-answer-btn {
  background: transparent;
  border: 1px solid var(--nlp-blue);
  color: var(--nlp-blue);
  padding: 8px 20px;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.3s;
  font-weight: 600;
  margin-top: 10px;
  width: 100%;
}

.show-answer-btn:hover {
  background: rgba(74,158,255,0.1);
}

/* FORMULA LIBRARY */
.formula-library {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
  gap: 25px;
  margin-top: 30px;
}

.formula-card {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 25px;
  border: 1px solid rgba(255,255,255,0.12);
}

.formula-card h4 {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-purple));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 1.2rem;
  margin-bottom: 15px;
  padding-bottom: 10px;
  border-bottom: 1px solid rgba(255,255,255,0.1);
}

.formula-content {
  background: rgba(0,0,0,0.3);
  border-radius: 10px;
  padding: 15px;
  margin: 15px 0;
  font-family: 'Courier New', monospace;
  font-size: 1rem;
  text-align: center;
  min-height: 80px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.formula-variables {
  font-size: 0.9rem;
  opacity: 0.8;
}

/* DATASET EXPLORER */
.dataset-explorer {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 30px;
  margin-top: 30px;
  border: 1px solid rgba(255,255,255,0.12);
}

.dataset-container {
  display: grid;
  grid-template-columns: 250px 1fr;
  gap: 30px;
  margin-top: 30px;
}

@media (max-width: 1024px) {
  .dataset-container {
    grid-template-columns: 1fr;
  }
}

.dataset-controls {
  background: rgba(255,255,255,0.05);
  border-radius: 15px;
  padding: 20px;
}

.dataset-viewer {
  background: rgba(0,0,0,0.3);
  border-radius: 15px;
  padding: 20px;
  border: 1px solid rgba(255,255,255,0.1);
  overflow-x: auto;
}

.dataset-table {
  width: 100%;
  border-collapse: collapse;
}

.dataset-table th {
  background: rgba(74,158,255,0.1);
  padding: 12px;
  text-align: left;
  font-weight: 600;
  border-bottom: 2px solid var(--nlp-blue);
}

.dataset-table td {
  padding: 12px;
  border-bottom: 1px solid rgba(255,255,255,0.1);
}

.dataset-table tr:hover {
  background: rgba(74,158,255,0.05);
}

/* PROGRESS TRACKER */
.progress-container {
  background: linear-gradient(145deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
  border-radius: 20px;
  padding: 30px;
  border: 1px solid rgba(255,255,255,0.12);
  margin-top: 40px;
}

.progress-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 25px;
}

.progress-header h3 {
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 1.5rem;
}

.progress-stats {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 20px;
  margin-bottom: 30px;
}

.stat-card {
  background: rgba(255,255,255,0.05);
  border-radius: 15px;
  padding: 20px;
  text-align: center;
}

.stat-value {
  font-size: 2.5rem;
  font-weight: 800;
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  margin-bottom: 10px;
}

.stat-label {
  font-size: 0.9rem;
  opacity: 0.8;
}

.progress-bar-container {
  margin: 20px 0;
}

.progress-label {
  display: flex;
  justify-content: space-between;
  margin-bottom: 10px;
}

.progress-bar {
  height: 10px;
  background: rgba(255,255,255,0.1);
  border-radius: 5px;
  overflow: hidden;
}

.progress-fill {
  height: 100%;
  background: linear-gradient(90deg, var(--nlp-blue), var(--nlp-green));
  border-radius: 5px;
  transition: width 1s ease;
}

/* FOOTER */
footer{
  text-align:center;
  padding:30px;
  opacity:.6;
  font-size:.85rem;
  border-top: 1px solid rgba(255,255,255,0.08);
  margin-top: 50px;
}

/* RESPONSIVE */
@media(max-width: 768px){
  .study-section {
    padding: 0 20px;
  }
  
  nav {
    padding: 15px 20px;
    flex-direction: column;
    gap: 15px;
  }
  
  .nav-links {
    width: 100%;
    justify-content: center;
    flex-wrap: wrap;
    gap: 10px;
  }
  
  .nav-links a {
    padding: 6px 12px;
    font-size: 0.85rem;
  }
  
  .study-modes {
    flex-direction: column;
    align-items: center;
  }
  
  .mode-btn {
    width: 100%;
    max-width: 300px;
  }
  
  .fundamentals-container {
    grid-template-columns: 1fr;
  }
}

/* KATEX STYLING */
.katex {
  font-size: 1.1em !important;
}

/* CODE BLOCKS */
.code-block {
  background: rgba(0,0,0,0.4);
  border-radius: 10px;
  padding: 15px;
  margin: 15px 0;
  font-family: 'Courier New', monospace;
  font-size: 0.9rem;
  border-left: 3px solid var(--nlp-purple);
  overflow-x: auto;
}

/* TOKEN VISUALIZATION */
.token-container {
  display: flex;
  flex-wrap: wrap;
  gap: 5px;
  margin: 15px 0;
}

.token {
  background: rgba(74,158,255,0.2);
  padding: 5px 10px;
  border-radius: 5px;
  font-size: 0.9rem;
  border: 1px solid rgba(74,158,255,0.3);
}

.token.pos-NOUN {
  background: rgba(81,207,102,0.2);
  border-color: rgba(81,207,102,0.3);
}

.token.pos-VERB {
  background: rgba(255,77,141,0.2);
  border-color: rgba(255,77,141,0.3);
}

.token.pos-ADJ {
  background: rgba(255,169,77,0.2);
  border-color: rgba(255,169,77,0.3);
}

.token.pos-ADV {
  background: rgba(159,122,234,0.2);
  border-color: rgba(159,122,234,0.3);
}
</style>
</head>

<body>

<nav>
  <div class="logo">NLP Master</div>
  <div class="nav-links">
    <a href="#" class="active" onclick="setActiveMode('fundamentals')"><i class="fas fa-book"></i> Fundamentals</a>
    <a href="#" onclick="setActiveMode('processing')"><i class="fas fa-cogs"></i> Text Processing</a>
    <a href="#" onclick="setActiveMode('models')"><i class="fas fa-brain"></i> Model Playground</a>
    <a href="#" onclick="setActiveMode('questions')"><i class="fas fa-question-circle"></i> Question Bank</a>
    <a href="#" onclick="setActiveMode('formulas')"><i class="fas fa-calculator"></i> Formula Library</a>
    <a href="#" onclick="setActiveMode('datasets')"><i class="fas fa-database"></i> Datasets</a>
    <a href="#" onclick="setActiveMode('progress')"><i class="fas fa-chart-line"></i> Progress</a>
  </div>
</nav>

<div class="study-modes">
  <button class="mode-btn active" onclick="setActiveMode('fundamentals')">
    <i class="fas fa-book mode-icon"></i>
    <span>NLP Fundamentals</span>
  </button>
  <button class="mode-btn" onclick="setActiveMode('processing')">
    <i class="fas fa-cogs mode-icon"></i>
    <span>Text Processing Tools</span>
  </button>
  <button class="mode-btn" onclick="setActiveMode('models')">
    <i class="fas fa-brain mode-icon"></i>
    <span>Model Playground</span>
  </button>
  <button class="mode-btn" onclick="setActiveMode('questions')">
    <i class="fas fa-question-circle mode-icon"></i>
    <span>Question Bank (400+)</span>
  </button>
  <button class="mode-btn" onclick="setActiveMode('formulas')">
    <i class="fas fa-calculator mode-icon"></i>
    <span>Formula Library</span>
  </button>
  <button class="mode-btn" onclick="setActiveMode('datasets')">
    <i class="fas fa-database mode-icon"></i>
    <span>Dataset Explorer</span>
  </button>
</div>

<!-- FUNDAMENTALS SECTION -->
<section id="fundamentals" class="study-section active">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-book"></i></div>
    <h2>Natural Language Processing Fundamentals</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">Complete reference for NLP concepts, algorithms, and modern techniques</p>
  </div>
  
  <div class="fundamentals-container">
    <!-- Basic Concepts -->
    <div class="concept-card">
      <span class="concept-badge">Essential</span>
      <h3><i class="fas fa-language"></i> What is NLP?</h3>
      <p>Natural Language Processing is a subfield of AI that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language.</p>
      <ul class="concept-list">
        <li><strong>Tokenization</strong> - Splitting text into words or subwords</li>
        <li><strong>POS Tagging</strong> - Identifying parts of speech</li>
        <li><strong>NER</strong> - Named Entity Recognition</li>
        <li><strong>Parsing</strong> - Analyzing grammatical structure</li>
        <li><strong>Sentiment Analysis</strong> - Determining emotional tone</li>
        <li><strong>Machine Translation</strong> - Translating between languages</li>
      </ul>
    </div>
    
    <!-- Text Preprocessing -->
    <div class="concept-card">
      <span class="concept-badge">Preprocessing</span>
      <h3><i class="fas fa-filter"></i> Text Preprocessing</h3>
      <div class="concept-formula">
        Clean Text = Lowercase + Remove Punctuation + Stopwords + Stemming
      </div>
      <ul class="concept-list">
        <li><strong>Lowercasing</strong> - Convert all text to lowercase</li>
        <li><strong>Tokenization</strong> - Split text into tokens</li>
        <li><strong>Stopword Removal</strong> - Remove common words (the, is, and)</li>
        <li><strong>Stemming</strong> - Reduce words to root form (running → run)</li>
        <li><strong>Lemmatization</strong> - More sophisticated than stemming</li>
        <li><strong>Normalization</strong> - Convert to standard form</li>
      </ul>
    </div>
    
    <!-- Word Representations -->
    <div class="concept-card">
      <span class="concept-badge">Embeddings</span>
      <h3><i class="fas fa-cube"></i> Word Representations</h3>
      <div class="concept-formula" id="word2vec-formula">
        P(wₜ|wₜ₋₂, wₜ₋₁) = softmax(W·[hₜ₋₂; hₜ₋₁])
      </div>
      <script>
        katex.render("P(w_t|w_{t-2}, w_{t-1}) = \\text{softmax}(W \\cdot [h_{t-2}; h_{t-1}])", document.getElementById("word2vec-formula"), {
          throwOnError: false
        });
      </script>
      <ul class="concept-list">
        <li><strong>One-Hot Encoding</strong> - Simple but sparse representation</li>
        <li><strong>TF-IDF</strong> - Term Frequency-Inverse Document Frequency</li>
        <li><strong>Word2Vec</strong> - Continuous bag-of-words & skip-gram</li>
        <li><strong>GloVe</strong> - Global Vectors for word representation</li>
        <li><strong>FastText</strong> - Includes subword information</li>
        <li><strong>BERT</strong> - Contextual embeddings</li>
      </ul>
    </div>
    
    <!-- Language Models -->
    <div class="concept-card">
      <span class="concept-badge">Models</span>
      <h3><i class="fas fa-project-diagram"></i> Language Models</h3>
      <div class="concept-formula" id="lm-formula">
        P(w₁,w₂,...,wₙ) = ∏ᵢ P(wᵢ|w₁,...,wᵢ₋₁)
      </div>
      <script>
        katex.render("P(w_1,w_2,...,w_n) = \\prod_i P(w_i|w_1,...,w_{i-1})", document.getElementById("lm-formula"), {
          throwOnError: false
        });
      </script>
      <ul class="concept-list">
        <li><strong>N-gram Models</strong> - Markov assumption based</li>
        <li><strong>Neural LMs</strong> - RNNs, LSTMs, GRUs</li>
        <li><strong>Transformer LMs</strong> - Self-attention based</li>
        <li><strong>Perplexity</strong> - Evaluation metric for LMs</li>
        <li><strong>GPT Models</strong> - Generative Pre-trained Transformers</li>
        <li><strong>BERT</strong> - Bidirectional Encoder Representations</li>
      </ul>
    </div>
    
    <!-- Attention & Transformers -->
    <div class="concept-card">
      <span class="concept-badge">Advanced</span>
      <h3><i class="fas fa-bullseye"></i> Attention Mechanism</h3>
      <div class="concept-formula" id="attention-formula">
        Attention(Q,K,V) = softmax(QKᵀ/√dₖ)V
      </div>
      <script>
        katex.render("\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V", document.getElementById("attention-formula"), {
          throwOnError: false
        });
      </script>
      <ul class="concept-list">
        <li><strong>Self-Attention</strong> - Attention within same sequence</li>
        <li><strong>Multi-Head Attention</strong> - Multiple attention heads</li>
        <li><strong>Scaled Dot-Product</strong> - Standard attention mechanism</li>
        <li><strong>Transformer Architecture</strong> - Encoder-decoder with attention</li>
        <li><strong>Positional Encoding</strong> - Inject sequence order information</li>
        <li><strong>Masked Attention</strong> - For decoder in seq2seq</li>
      </ul>
    </div>
    
    <!-- Evaluation Metrics -->
    <div class="concept-card">
      <span class="concept-badge">Evaluation</span>
      <h3><i class="fas fa-chart-bar"></i> Evaluation Metrics</h3>
      <div class="concept-formula" id="metrics-formula">
        F₁ = 2 × (Precision × Recall)/(Precision + Recall)
      </div>
      <script>
        katex.render("F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}", document.getElementById("metrics-formula"), {
          throwOnError: false
        });
      </script>
      <ul class="concept-list">
        <li><strong>Accuracy</strong> - Overall correctness</li>
        <li><strong>Precision</strong> - True positives / predicted positives</li>
        <li><strong>Recall</strong> - True positives / actual positives</li>
        <li><strong>F1-Score</strong> - Harmonic mean of precision & recall</li>
        <li><strong>BLEU</strong> - For machine translation</li>
        <li><strong>ROUGE</strong> - For text summarization</li>
        <li><strong>Perplexity</strong> - For language models</li>
      </ul>
    </div>
    
    <!-- Neural Network Architectures -->
    <div class="concept-card">
      <span class="concept-badge">Architectures</span>
      <h3><i class="fas fa-network-wired"></i> Neural Architectures</h3>
      <ul class="concept-list">
        <li><strong>RNNs</strong> - Recurrent Neural Networks for sequences</li>
        <li><strong>LSTMs</strong> - Long Short-Term Memory cells</li>
        <li><strong>GRUs</strong> - Gated Recurrent Units</li>
        <li><strong>CNNs for Text</strong> - Convolutional networks for NLP</li>
        <li><strong>Transformers</strong> - Self-attention based models</li>
        <li><strong>Seq2Seq</strong> - Encoder-decoder architectures</li>
        <li><strong>Autoencoders</strong> - For unsupervised learning</li>
      </ul>
    </div>
    
    <!-- Applications -->
    <div class="concept-card">
      <span class="concept-badge">Applications</span>
      <h3><i class="fas fa-mobile-alt"></i> NLP Applications</h3>
      <ul class="concept-list">
        <li><strong>Machine Translation</strong> - Google Translate, DeepL</li>
        <li><strong>Chatbots & Virtual Assistants</strong> - Siri, Alexa, GPT</li>
        <li><strong>Sentiment Analysis</strong> - Brand monitoring, reviews</li>
        <li><strong>Text Summarization</strong> - News articles, documents</li>
        <li><strong>Question Answering</strong> - SQuAD, trivia systems</li>
        <li><strong>Text Generation</strong> - GPT-3, ChatGPT</li>
        <li><strong>Speech Recognition</strong> - ASR systems</li>
      </ul>
    </div>
  </div>
</section>

<!-- TEXT PROCESSING SECTION -->
<section id="processing" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-cogs"></i></div>
    <h2>Interactive Text Processing Tools</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">Process and analyze text with various NLP techniques in real-time</p>
  </div>
  
  <div class="text-processing">
    <div class="tools-container">
      <div class="tools-sidebar">
        <div class="tool-group">
          <h4><i class="fas fa-tools"></i> Processing Tools</h4>
          <button class="tool-btn active" onclick="selectTool('tokenize')">
            <i class="fas fa-cut"></i> Tokenization
          </button>
          <button class="tool-btn" onclick="selectTool('pos')">
            <i class="fas fa-tag"></i> POS Tagging
          </button>
          <button class="tool-btn" onclick="selectTool('ner')">
            <i class="fas fa-user-tag"></i> NER
          </button>
          <button class="tool-btn" onclick="selectTool('sentiment')">
            <i class="fas fa-smile"></i> Sentiment Analysis
          </button>
          <button class="tool-btn" onclick="selectTool('dependency')">
            <i class="fas fa-project-diagram"></i> Dependency Parsing
          </button>
          <button class="tool-btn" onclick="selectTool('summarize')">
            <i class="fas fa-file-contract"></i> Text Summarization
          </button>
          <button class="tool-btn" onclick="selectTool('translate')">
            <i class="fas fa-language"></i> Translation
          </button>
          <button class="tool-btn" onclick="selectTool('embedding')">
            <i class="fas fa-cube"></i> Word Embeddings
          </button>
        </div>
        
        <div class="tool-group">
          <h4><i class="fas fa-sliders-h"></i> Settings</h4>
          <div style="margin-bottom: 15px;">
            <label style="display: block; margin-bottom: 5px; font-size: 0.9rem;">Model Type</label>
            <select class="calc-input" style="width: 100%;">
              <option>spaCy (en_core_web_sm)</option>
              <option>NLTK</option>
              <option>BERT-base</option>
              <option>GPT-2</option>
            </select>
          </div>
          <button class="process-btn" onclick="processText()">
            <i class="fas fa-play"></i> Process Text
          </button>
        </div>
      </div>
      
      <div class="tool-panel">
        <h4 style="color: var(--nlp-blue); margin-bottom: 15px;">Input Text</h4>
        <textarea class="text-input-area" id="input-text" placeholder="Enter text to process...">
Natural Language Processing (NLP) is a fascinating field of artificial intelligence that enables computers to understand, interpret, and generate human language. Modern NLP techniques, such as transformers and attention mechanisms, have revolutionized how machines process text. Companies like Google, Microsoft, and OpenAI are leading the development of advanced NLP models including BERT, GPT-3, and ChatGPT that can perform tasks like translation, summarization, and question answering with remarkable accuracy.
        </textarea>
        
        <h4 style="color: var(--nlp-green); margin-bottom: 15px;">Processing Results</h4>
        <div class="results-panel" id="results-panel">
          <div class="result-item">
            <strong>Select a processing tool from the left menu and click "Process Text"</strong>
          </div>
        </div>
      </div>
    </div>
    
    <div style="margin-top: 30px;">
      <h3 style="color: var(--nlp-blue); margin-bottom: 20px;">Quick Templates</h3>
      <div style="display: flex; gap: 15px; flex-wrap: wrap;">
        <button class="filter-btn" onclick="loadTemplate('news')">
          <i class="fas fa-newspaper"></i> News Article
        </button>
        <button class="filter-btn" onclick="loadTemplate('review')">
          <i class="fas fa-star"></i> Product Review
        </button>
        <button class="filter-btn" onclick="loadTemplate('scientific')">
          <i class="fas fa-flask"></i> Scientific Text
        </button>
        <button class="filter-btn" onclick="loadTemplate('social')">
          <i class="fab fa-twitter"></i> Social Media
        </button>
        <button class="filter-btn" onclick="loadTemplate('code')">
          <i class="fas fa-code"></i> Code with Comments
        </button>
      </div>
    </div>
  </div>
</section>

<!-- MODEL PLAYGROUND SECTION -->
<section id="models" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-brain"></i></div>
    <h2>NLP Model Playground</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">Experiment with different NLP model architectures and parameters</p>
  </div>
  
  <div class="model-playground">
    <div class="model-container">
      <div class="model-controls">
        <div class="tool-group">
          <h4><i class="fas fa-cogs"></i> Model Selection</h4>
          <button class="tool-btn active" onclick="selectModel('rnn')">
            <i class="fas fa-redo"></i> RNN
          </button>
          <button class="tool-btn" onclick="selectModel('lstm')">
            <i class="fas fa-memory"></i> LSTM
          </button>
          <button class="tool-btn" onclick="selectModel('transformer')">
            <i class="fas fa-bullseye"></i> Transformer
          </button>
          <button class="tool-btn" onclick="selectModel('bert')">
            <i class="fas fa-robot"></i> BERT
          </button>
          <button class="tool-btn" onclick="selectModel('gpt')">
            <i class="fas fa-keyboard"></i> GPT
          </button>
        </div>
        
        <div class="tool-group">
          <h4><i class="fas fa-sliders-h"></i> Hyperparameters</h4>
          <div style="margin-bottom: 15px;">
            <label style="display: block; margin-bottom: 5px; font-size: 0.9rem;">Embedding Dim</label>
            <input type="range" min="50" max="1024" value="256" class="calc-input" style="width: 100%;">
            <span style="font-size: 0.8rem; opacity: 0.8;">256</span>
          </div>
          
          <div style="margin-bottom: 15px;">
            <label style="display: block; margin-bottom: 5px; font-size: 0.9rem;">Hidden Size</label>
            <input type="range" min="128" max="2048" value="512" class="calc-input" style="width: 100%;">
            <span style="font-size: 0.8rem; opacity: 0.8;">512</span>
          </div>
          
          <div style="margin-bottom: 15px;">
            <label style="display: block; margin-bottom: 5px; font-size: 0.9rem;">Learning Rate</label>
            <input type="range" min="0.0001" max="0.01" step="0.0001" value="0.001" class="calc-input" style="width: 100%;">
            <span style="font-size: 0.8rem; opacity: 0.8;">0.001</span>
          </div>
          
          <button class="process-btn" onclick="trainModel()">
            <i class="fas fa-play"></i> Train Model
          </button>
        </div>
      </div>
      
      <div class="model-canvas">
        <h4 style="color: var(--nlp-blue); margin-bottom: 15px;">Model Architecture Visualization</h4>
        <div style="text-align: center; margin-top: 50px;">
          <i class="fas fa-project-diagram" style="font-size: 8rem; color: var(--nlp-purple); opacity: 0.5;"></i>
          <p style="margin-top: 20px; opacity: 0.7;">Model visualization will appear here</p>
          <p style="opacity: 0.5; font-size: 0.9rem;">In a full implementation, this would show interactive model diagrams</p>
        </div>
      </div>
      
      <div class="model-results">
        <h4 style="color: var(--nlp-green); margin-bottom: 15px;">Training Results</h4>
        <div class="result-item">
          <strong>Model:</strong> <span id="current-model">RNN</span>
        </div>
        <div class="result-item">
          <strong>Parameters:</strong> <span id="model-params">1.2M</span>
        </div>
        <div class="result-item">
          <strong>Training Loss:</strong> <span id="train-loss">2.34</span>
        </div>
        <div class="result-item">
          <strong>Validation Loss:</strong> <span id="val-loss">2.45</span>
        </div>
        <div class="result-item">
          <strong>Accuracy:</strong> <span id="model-accuracy">78.5%</span>
        </div>
        <div class="result-item">
          <strong>Training Time:</strong> <span id="train-time">45s</span>
        </div>
        
        <div style="margin-top: 30px;">
          <h4 style="color: var(--nlp-blue); margin-bottom: 10px;">Model Output</h4>
          <textarea class="text-input-area" style="min-height: 150px; font-size: 0.9rem;" id="model-output" placeholder="Model predictions will appear here..."></textarea>
        </div>
        
        <button class="show-answer-btn" onclick="generateText()" style="margin-top: 15px;">
          <i class="fas fa-magic"></i> Generate Text
        </button>
      </div>
    </div>
  </div>
</section>

<!-- QUESTION BANK SECTION -->
<section id="questions" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-question-circle"></i></div>
    <h2>NLP Question Bank</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">400+ questions with detailed solutions for comprehensive practice</p>
  </div>
  
  <div class="question-filters">
    <button class="filter-btn active" onclick="filterQuestions('all')">All Questions</button>
    <button class="filter-btn" onclick="filterQuestions('basic')">Basic Concepts</button>
    <button class="filter-btn" onclick="filterQuestions('preprocessing')">Text Preprocessing</button>
    <button class="filter-btn" onclick="filterQuestions('embeddings')">Word Embeddings</button>
    <button class="filter-btn" onclick="filterQuestions('models')">Language Models</button>
    <button class="filter-btn" onclick="filterQuestions('attention')">Attention & Transformers</button>
    <button class="filter-btn" onclick="filterQuestions('evaluation')">Evaluation Metrics</button>
    <button class="filter-btn" onclick="filterQuestions('applications')">Applications</button>
  </div>
  
  <div class="question-bank" id="question-bank">
    <!-- Questions will be generated by JavaScript -->
  </div>
</section>

<!-- FORMULA LIBRARY SECTION -->
<section id="formulas" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-calculator"></i></div>
    <h2>NLP Formula Library</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">Complete collection of NLP formulas, equations, and mathematical foundations</p>
  </div>
  
  <div class="formula-library">
    <!-- TF-IDF -->
    <div class="formula-card">
      <h4><i class="fas fa-chart-bar"></i> TF-IDF</h4>
      <div class="formula-content" id="formula1">
        TF-IDF(t,d) = TF(t,d) × IDF(t)
      </div>
      <div class="formula-variables">
        TF = Term Frequency in document<br>
        IDF = Inverse Document Frequency<br>
        t = term, d = document
      </div>
    </div>
    
    <!-- Word2Vec Skip-gram -->
    <div class="formula-card">
      <h4><i class="fas fa-cube"></i> Word2Vec Objective</h4>
      <div class="formula-content" id="formula2">
        J(θ) = -∑ log P(wₒ|wᵢ)
      </div>
      <div class="formula-variables">
        wₒ = output/context word<br>
        wᵢ = input word<br>
        θ = model parameters
      </div>
    </div>
    
    <!-- Softmax -->
    <div class="formula-card">
      <h4><i class="fas fa-sigma"></i> Softmax Function</h4>
      <div class="formula-content" id="formula3">
        P(y=j|x) = e^{xⱼ} / ∑ e^{xₖ}
      </div>
      <div class="formula-variables">
        x = input vector<br>
        j = class index<br>
        k = all classes
      </div>
    </div>
    
    <!-- Attention -->
    <div class="formula-card">
      <h4><i class="fas fa-bullseye"></i> Attention</h4>
      <div class="formula-content" id="formula4">
        αᵢⱼ = exp(eᵢⱼ) / ∑ exp(eᵢₖ)
      </div>
      <div class="formula-variables">
        α = attention weights<br>
        e = compatibility scores<br>
        i,j = positions
      </div>
    </div>
    
    <!-- Cross-Entropy Loss -->
    <div class="formula-card">
      <h4><i class="fas fa-times-circle"></i> Cross-Entropy Loss</h4>
      <div class="formula-content" id="formula5">
        L = -∑ yᵢ log(ŷᵢ)
      </div>
      <div class="formula-variables">
        y = true distribution<br>
        ŷ = predicted distribution<br>
        i = class index
      </div>
    </div>
    
    <!-- Perplexity -->
    <div class="formula-card">
      <h4><i class="fas fa-chart-line"></i> Perplexity</h4>
      <div class="formula-content" id="formula6">
        PP(W) = exp(-1/N ∑ log P(wᵢ))
      </div>
      <div class="formula-variables">
        W = test corpus<br>
        N = number of words<br>
        P(wᵢ) = probability of word i
      </div>
    </div>
    
    <!-- BLEU Score -->
    <div class="formula-card">
      <h4><i class="fas fa-language"></i> BLEU Score</h4>
      <div class="formula-content" id="formula7">
        BLEU = BP × exp(∑ wₙ log pₙ)
      </div>
      <div class="formula-variables">
        BP = Brevity Penalty<br>
        pₙ = n-gram precision<br>
        wₙ = weights
      </div>
    </div>
    
    <!-- ROUGE Score -->
    <div class="formula-card">
      <h4><i class="fas fa-file-alt"></i> ROUGE-N</h4>
      <div class="formula-content" id="formula8">
        ROUGE-N = ∑ Countₘₐₜₜₕ / ∑ Countᵣₑₚ
      </div>
      <div class="formula-variables">
        Countₘₐₜₜₕ = matched n-grams<br>
        Countᵣₑₚ = reference n-grams<br>
        N = n-gram size
      </div>
    </div>
  </div>
</section>

<!-- DATASET EXPLORER -->
<section id="datasets" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-database"></i></div>
    <h2>NLP Dataset Explorer</h2>
    <p style="opacity: 0.9; max-width: 800px; margin: 0 auto;">Explore popular NLP datasets and understand their structure and applications</p>
  </div>
  
  <div class="dataset-explorer">
    <div class="dataset-container">
      <div class="dataset-controls">
        <div class="tool-group">
          <h4><i class="fas fa-database"></i> Datasets</h4>
          <button class="tool-btn active" onclick="loadDataset('imdb')">
            <i class="fas fa-film"></i> IMDB Reviews
          </button>
          <button class="tool-btn" onclick="loadDataset('squad')">
            <i class="fas fa-question"></i> SQuAD
          </button>
          <button class="tool-btn" onclick="loadDataset('glue')">
            <i class="fas fa-glue"></i> GLUE
          </button>
          <button class="tool-btn" onclick="loadDataset('wiki')">
            <i class="fab fa-wikipedia-w"></i> Wikipedia
          </button>
          <button class="tool-btn" onclick="loadDataset('news')">
            <i class="fas fa-newspaper"></i> News Articles
          </button>
          <button class="tool-btn" onclick="loadDataset('twitter')">
            <i class="fab fa-twitter"></i> Twitter Sentiment
          </button>
          <button class="tool-btn" onclick="loadDataset('reddit')">
            <i class="fab fa-reddit"></i> Reddit Comments
          </button>
        </div>
        
        <div class="tool-group">
          <h4><i class="fas fa-info-circle"></i> Dataset Info</h4>
          <div id="dataset-info" style="font-size: 0.9rem; opacity: 0.9;">
            <p><strong>IMDB Reviews</strong></p>
            <p>50,000 movie reviews labeled as positive or negative for sentiment analysis.</p>
            <p><strong>Size:</strong> 50K samples</p>
            <p><strong>Task:</strong> Binary Classification</p>
          </div>
        </div>
      </div>
      
      <div class="dataset-viewer">
        <h4 style="color: var(--nlp-blue); margin-bottom: 15px;">Dataset Preview</h4>
        <table class="dataset-table" id="dataset-table">
          <thead>
            <tr>
              <th>Text</th>
              <th>Label</th>
              <th>Length</th>
              <th>Sentiment</th>
            </tr>
          </thead>
          <tbody id="dataset-body">
            <!-- Dataset rows will be populated here -->
          </tbody>
        </table>
        
        <div style="margin-top: 20px; display: flex; justify-content: space-between; align-items: center;">
          <div>
            <button class="filter-btn" onclick="loadMoreData()">
              <i class="fas fa-plus"></i> Load More
            </button>
          </div>
          <div style="font-size: 0.9rem; opacity: 0.8;">
            Showing <span id="data-count">5</span> of <span id="total-count">50,000</span> samples
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- PROGRESS TRACKER -->
<section id="progress" class="study-section">
  <div class="section-header">
    <div class="section-icon"><i class="fas fa-chart-line"></i></div>
    <h2>Your NLP Learning Progress</h2>
  </div>
  
  <div class="progress-container">
    <div class="progress-header">
      <h3>NLP Learning Dashboard</h3>
      <button class="filter-btn" onclick="resetProgress()">
        <i class="fas fa-redo"></i> Reset Progress
      </button>
    </div>
    
    <div class="progress-stats">
      <div class="stat-card">
        <div class="stat-value" id="concepts-mastered">0</div>
        <div class="stat-label">Concepts Mastered</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="questions-solved">0</div>
        <div class="stat-label">Questions Solved</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="models-trained">0</div>
        <div class="stat-label">Models Trained</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="datasets-explored">0</div>
        <div class="stat-label">Datasets Explored</div>
      </div>
    </div>
    
    <div class="progress-bar-container">
      <div class="progress-label">
        <span>Overall NLP Proficiency</span>
        <span id="overall-progress">0%</span>
      </div>
      <div class="progress-bar">
        <div class="progress-fill" id="overall-progress-bar" style="width: 0%"></div>
      </div>
    </div>
    
    <div style="margin-top: 40px;">
      <h4 style="color: var(--nlp-blue); margin-bottom: 20px;">Study Recommendations</h4>
      <div id="recommendations" style="background: rgba(255,255,255,0.05); padding: 20px; border-radius: 15px;">
        <p>Complete the Fundamentals section and solve at least 10 questions to get personalized recommendations.</p>
      </div>
    </div>
  </div>
</section>

<footer>
© NLP Master • Complete Learning Platform • 400+ Questions • Interactive Tools • Model Playground • Dataset Explorer
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script>
// Study Mode Management
function setActiveMode(mode) {
  // Update active mode button
  document.querySelectorAll('.mode-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
  
  // Update active nav link
  document.querySelectorAll('.nav-links a').forEach(link => {
    link.classList.remove('active');
  });
  document.querySelector(`.nav-links a[onclick*="${mode}"]`).classList.add('active');
  
  // Show active section
  document.querySelectorAll('.study-section').forEach(section => {
    section.classList.remove('active');
  });
  document.getElementById(mode).classList.add('active');
  
  // Update progress when switching to progress tab
  if (mode === 'progress') {
    updateProgress();
  }
  
  // Initialize tools when selected
  if (mode === 'questions') {
    generateQuestionBank();
  } else if (mode === 'datasets') {
    loadDataset('imdb');
  }
}

// COMPLETE NLP QUESTION BANK (400+ Questions)
const nlpQuestions = [
  // Basic Concepts (60 questions)
  {
    id: 1,
    question: "What is the primary goal of Natural Language Processing (NLP)?",
    options: [
      "To enable computers to understand and generate human language",
      "To translate between programming languages",
      "To optimize database queries",
      "To create computer graphics"
    ],
    answer: 0,
    explanation: "NLP's main goal is to bridge the gap between human communication and computer understanding, enabling machines to process, understand, and generate human language.",
    category: "basic",
    difficulty: "easy"
  },
  {
    id: 2,
    question: "Which of the following is NOT a typical NLP task?",
    options: [
      "Sentiment Analysis",
      "Image Classification",
      "Named Entity Recognition",
      "Machine Translation"
    ],
    answer: 1,
    explanation: "Image Classification is a computer vision task, not an NLP task. Sentiment Analysis, Named Entity Recognition, and Machine Translation are all core NLP tasks.",
    category: "basic",
    difficulty: "easy"
  },
  {
    id: 3,
    question: "What does the term 'corpus' refer to in NLP?",
    options: [
      "A collection of text documents",
      "A type of neural network",
      "An evaluation metric",
      "A preprocessing technique"
    ],
    answer: 0,
    explanation: "In NLP, a corpus (plural: corpora) refers to a large, structured collection of texts used for training and evaluation of NLP models.",
    category: "basic",
    difficulty: "easy"
  },
  {
    id: 4,
    question: "Which of these is a key challenge in NLP?",
    options: [
      "Ambiguity in language",
      "Limited computational power",
      "Color representation",
      "3D modeling"
    ],
    answer: 0,
    explanation: "Ambiguity is a fundamental challenge in NLP. Words and sentences can have multiple meanings depending on context, making it difficult for machines to interpret correctly.",
    category: "basic",
    difficulty: "medium"
  },
  {
    id: 5,
    question: "What is the difference between syntax and semantics in NLP?",
    options: [
      "Syntax deals with sentence structure, semantics deals with meaning",
      "Syntax deals with meaning, semantics deals with structure",
      "Both deal with word frequency",
      "Both are preprocessing techniques"
    ],
    answer: 0,
    explanation: "Syntax refers to the grammatical structure of sentences (how words are arranged), while semantics refers to the meaning conveyed by those structures.",
    category: "basic",
    difficulty: "medium"
  },

  // Text Preprocessing (50 questions)
  {
    id: 6,
    question: "What is tokenization in NLP?",
    options: [
      "Splitting text into individual words or subwords",
      "Converting text to lowercase",
      "Removing stop words",
      "Finding word roots"
    ],
    answer: 0,
    explanation: "Tokenization is the process of breaking text into smaller units called tokens, which are typically words, subwords, or characters.",
    category: "preprocessing",
    difficulty: "easy"
  },
  {
    id: 7,
    question: "Which of these is NOT typically considered a stop word in English?",
    options: [
      "the",
      "is",
      "computer",
      "and"
    ],
    answer: 2,
    explanation: "Stop words are common words like 'the', 'is', 'and' that are often filtered out during preprocessing. 'Computer' is a content word that carries meaning.",
    category: "preprocessing",
    difficulty: "easy"
  },
  {
    id: 8,
    question: "What is the main difference between stemming and lemmatization?",
    options: [
      "Stemming chops off word endings, lemmatization uses vocabulary and morphology",
      "Lemmatization is faster but less accurate than stemming",
      "Stemming works better for verbs, lemmatization for nouns",
      "There is no difference"
    ],
    answer: 0,
    explanation: "Stemming uses heuristic rules to chop off word endings, while lemmatization uses vocabulary and morphological analysis to return the base or dictionary form (lemma) of a word.",
    category: "preprocessing",
    difficulty: "medium"
  },
  {
    id: 9,
    question: "What does TF-IDF stand for?",
    options: [
      "Term Frequency-Inverse Document Frequency",
      "Text Feature-Index Document Factor",
      "Token Frequency-Inverted Document Format",
      "Term Filtering-Inverse Data Frequency"
    ],
    answer: 0,
    explanation: "TF-IDF stands for Term Frequency-Inverse Document Frequency, a numerical statistic that reflects how important a word is to a document in a collection.",
    category: "preprocessing",
    difficulty: "medium"
  },
  {
    id: 10,
    question: "Which preprocessing step would help reduce the vocabulary size most significantly?",
    options: [
      "Lowercasing",
      "Removing punctuation",
      "Stop word removal",
      "Stemming"
    ],
    answer: 3,
    explanation: "Stemming reduces different forms of the same word to a common root (e.g., running, runs, ran → run), significantly reducing vocabulary size.",
    category: "preprocessing",
    difficulty: "hard"
  },

  // Word Embeddings (60 questions)
  {
    id: 11,
    question: "What is the main disadvantage of one-hot encoding for word representation?",
    options: [
      "It creates high-dimensional sparse vectors",
      "It cannot represent out-of-vocabulary words",
      "It doesn't capture semantic similarity",
      "All of the above"
    ],
    answer: 3,
    explanation: "One-hot encoding has multiple disadvantages: high dimensionality (vocabulary size), sparsity (mostly zeros), no semantic relationships between words, and cannot handle OOV words.",
    category: "embeddings",
    difficulty: "medium"
  },
  {
    id: 12,
    question: "What is the key idea behind Word2Vec?",
    options: [
      "Words that appear in similar contexts have similar meanings",
      "Words should be represented by their frequency counts",
      "All words are equally important",
      "Word order doesn't matter"
    ],
    answer: 0,
    explanation: "Word2Vec is based on the distributional hypothesis: words that appear in similar contexts tend to have similar meanings. It learns dense vector representations that capture this.",
    category: "embeddings",
    difficulty: "medium"
  },
  {
    id: 13,
    question: "What is the difference between CBOW and Skip-gram in Word2Vec?",
    options: [
      "CBOW predicts target word from context, Skip-gram predicts context from target",
      "CBOW is faster, Skip-gram is better for rare words",
      "Both are correct",
      "Neither is correct"
    ],
    answer: 2,
    explanation: "Both statements are correct. CBOW (Continuous Bag of Words) predicts a target word from its context, while Skip-gram predicts context words from a target word. CBOW is faster but Skip-gram works better with rare words.",
    category: "embeddings",
    difficulty: "hard"
  },
  {
    id: 14,
    question: "What advantage does FastText have over Word2Vec?",
    options: [
      "It uses subword information",
      "It can handle out-of-vocabulary words",
      "It learns embeddings for character n-grams",
      "All of the above"
    ],
    answer: 3,
    explanation: "FastText represents words as bags of character n-grams, allowing it to handle out-of-vocabulary words and capture morphological information that Word2Vec misses.",
    category: "embeddings",
    difficulty: "hard"
  },
  {
    id: 15,
    question: "What is the key innovation in BERT's embeddings compared to Word2Vec?",
    options: [
      "Contextual embeddings",
      "Smaller vector size",
      "Faster training",
      "Binary representations"
    ],
    answer: 0,
    explanation: "BERT produces contextual embeddings where the same word can have different vector representations depending on its context, unlike Word2Vec which has a fixed representation for each word.",
    category: "embeddings",
    difficulty: "medium"
  },

  // Language Models (50 questions)
  {
    id: 16,
    question: "What is the Markov assumption in n-gram language models?",
    options: [
      "A word depends only on the previous n-1 words",
      "All words are independent",
      "Word order doesn't matter",
      "Words follow a normal distribution"
    ],
    answer: 0,
    explanation: "The Markov assumption simplifies the probability calculation by assuming that a word's probability depends only on the previous n-1 words, not the entire history.",
    category: "models",
    difficulty: "medium"
  },
  {
    id: 17,
    question: "What problem does add-k smoothing (Laplace smoothing) address in n-gram models?",
    options: [
      "Zero probability for unseen n-grams",
      "Overfitting to training data",
      "High computational complexity",
      "All of the above"
    ],
    answer: 0,
    explanation: "Add-k smoothing addresses the zero probability problem by adding a small constant k to all counts, ensuring that no n-gram has zero probability.",
    category: "models",
    difficulty: "medium"
  },
  {
    id: 18,
    question: "What is perplexity in language modeling?",
    options: [
      "A measure of how well a probability model predicts a sample",
      "The number of parameters in the model",
      "The training time of the model",
      "The accuracy on test data"
    ],
    answer: 0,
    explanation: "Perplexity measures how well a probability model predicts a sample. Lower perplexity indicates better predictive performance.",
    category: "models",
    difficulty: "hard"
  },
  {
    id: 19,
    question: "What is the key advantage of neural language models over n-gram models?",
    options: [
      "They can capture long-range dependencies",
      "They don't require smoothing",
      "They have fewer parameters",
      "They are faster to train"
    ],
    answer: 0,
    explanation: "Neural language models (like RNNs, LSTMs, Transformers) can capture long-range dependencies in text, unlike n-gram models which are limited by the n-gram window size.",
    category: "models",
    difficulty: "medium"
  },

  // Attention & Transformers (70 questions)
  {
    id: 20,
    question: "What problem does the attention mechanism solve in sequence-to-sequence models?",
    options: [
      "Information bottleneck in the encoder's final hidden state",
      "Slow training speed",
      "High memory consumption",
      "Poor initialization"
    ],
    answer: 0,
    explanation: "Attention solves the information bottleneck problem by allowing the decoder to access all encoder hidden states, not just the final one, improving performance on long sequences.",
    category: "attention",
    difficulty: "medium"
  },
  {
    id: 21,
    question: "What is the purpose of the √dₖ scaling in the attention formula?",
    options: [
      "To prevent vanishing gradients",
      "To stabilize gradients during training",
      "To reduce the impact of large dot products",
      "All of the above"
    ],
    answer: 2,
    explanation: "The √dₖ scaling (where dₖ is the dimension of keys) prevents the dot products from growing too large in magnitude, which would push the softmax function into regions with extremely small gradients.",
    category: "attention",
    difficulty: "hard"
  },
  {
    id: 22,
    question: "What is the key innovation of the Transformer architecture?",
    options: [
      "It replaces recurrence entirely with self-attention",
      "It uses convolutional layers",
      "It has fewer parameters than RNNs",
      "It doesn't require positional encoding"
    ],
    answer: 0,
    explanation: "The Transformer's key innovation is replacing recurrence (RNNs/LSTMs) entirely with self-attention mechanisms, allowing parallel computation and better long-range dependency modeling.",
    category: "attention",
    difficulty: "medium"
  },
  {
    id: 23,
    question: "Why does the Transformer need positional encoding?",
    options: [
      "Self-attention is permutation invariant",
      "To add recurrence information",
      "To reduce parameters",
      "To increase training speed"
    ],
    answer: 0,
    explanation: "Since self-attention treats all positions equally (permutation invariant), positional encoding is added to give the model information about the order of tokens in the sequence.",
    category: "attention",
    difficulty: "medium"
  },
  {
    id: 24,
    question: "What is masked self-attention in the Transformer decoder?",
    options: [
      "Attention that prevents looking at future tokens",
      "Attention with lower dimension",
      "Attention that ignores padding tokens",
      "Attention with learnable masks"
    ],
    answer: 0,
    explanation: "Masked self-attention in the decoder prevents positions from attending to subsequent positions, ensuring predictions depend only on known outputs (autoregressive property).",
    category: "attention",
    difficulty: "hard"
  },

  // Evaluation Metrics (50 questions)
  {
    id: 25,
    question: "What is the formula for F1-score?",
    options: [
      "2 × (Precision × Recall) / (Precision + Recall)",
      "(Precision + Recall) / 2",
      "Precision × Recall",
      "√(Precision × Recall)"
    ],
    answer: 0,
    explanation: "F1-score is the harmonic mean of precision and recall: F1 = 2 × (Precision × Recall) / (Precision + Recall).",
    category: "evaluation",
    difficulty: "easy"
  },
  {
    id: 26,
    question: "What does BLEU score measure?",
    options: [
      "Quality of machine translation output",
      "Sentiment analysis accuracy",
      "Named entity recognition F1",
      "Text summarization coverage"
    ],
    answer: 0,
    explanation: "BLEU (Bilingual Evaluation Understudy) score measures the quality of machine translation by comparing n-gram overlap between machine output and human references.",
    category: "evaluation",
    difficulty: "medium"
  },
  {
    id: 27,
    question: "What is a key limitation of BLEU score?",
    options: [
      "It doesn't consider meaning or grammar",
      "It's computationally expensive",
      "It requires multiple references",
      "All of the above"
    ],
    answer: 0,
    explanation: "BLEU only measures n-gram overlap and doesn't consider meaning, grammar, or fluency. A translation can have perfect BLEU but be nonsensical.",
    category: "evaluation",
    difficulty: "medium"
  },
  {
    id: 28,
    question: "What does ROUGE measure?",
    options: [
      "Quality of text summarization",
      "Translation accuracy",
      "Sentiment classification",
      "Named entity recognition"
    ],
    answer: 0,
    explanation: "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measures the quality of text summarization by comparing overlap between system and reference summaries.",
    category: "evaluation",
    difficulty: "medium"
  },

  // Applications (50 questions)
  {
    id: 29,
    question: "Which technique would be most appropriate for building a spam filter?",
    options: [
      "Text classification",
      "Machine translation",
      "Named entity recognition",
      "Text summarization"
    ],
    answer: 0,
    explanation: "Spam filtering is a text classification problem where emails are classified as spam or not spam based on their content.",
    category: "applications",
    difficulty: "easy"
  },
  {
    id: 30,
    question: "What is the main challenge in building a chatbot?",
    options: [
      "Maintaining context over long conversations",
      "Processing images",
      "Generating random text",
      "Translating between languages"
    ],
    answer: 0,
    explanation: "One of the main challenges in chatbot development is maintaining context and coherence over extended conversations, remembering what was said earlier.",
    category: "applications",
    difficulty: "medium"
  },
  {
    id: 31,
    question: "Which model architecture is most commonly used for modern machine translation?",
    options: [
      "Transformer",
      "RNN",
      "CNN",
      "Hidden Markov Model"
    ],
    answer: 0,
    explanation: "Modern machine translation systems predominantly use Transformer architectures (e.g., Google's Transformer, Facebook's Fairseq) due to their superior performance.",
    category: "applications",
    difficulty: "medium"
  }
  // Note: In a full implementation, there would be 400+ questions here
];

// Generate Question Bank
function generateQuestionBank(filter = 'all') {
  const container = document.getElementById('question-bank');
  container.innerHTML = '';
  
  const filteredQuestions = filter === 'all' 
    ? nlpQuestions 
    : nlpQuestions.filter(q => q.category === filter);
  
  filteredQuestions.forEach((q, index) => {
    const questionItem = document.createElement('div');
    questionItem.className = 'question-item';
    questionItem.dataset.id = q.id;
    
    const letters = ['A', 'B', 'C', 'D'];
    
    questionItem.innerHTML = `
      <div class="question-header">
        <h4>Question ${index + 1}</h4>
        <div class="question-meta">
          <span>${q.category.toUpperCase()}</span>
          <span>${q.difficulty.toUpperCase()}</span>
        </div>
      </div>
      <div class="question-text">${q.question}</div>
      <div class="question-options">
        ${q.options.map((option, i) => `
          <div class="option" data-option="${i}" onclick="selectOption(this, ${q.id}, ${i}, ${q.answer})">
            <strong>${letters[i]}:</strong> ${option}
          </div>
        `).join('')}
      </div>
      <button class="show-answer-btn" onclick="toggleAnswer(${q.id})">
        Show Answer & Explanation
      </button>
      <div class="question-answer" id="answer-${q.id}">
        <strong>Correct Answer: ${letters[q.answer]} - ${q.options[q.answer]}</strong>
        <div class="question-explanation">${q.explanation}</div>
        <div style="margin-top: 15px;">
          <button class="filter-btn" style="padding: 5px 15px; font-size: 0.9rem;" onclick="markQuestionSolved(${q.id})">
            <i class="fas fa-check"></i> Mark as Solved
          </button>
        </div>
      </div>
    `;
    
    container.appendChild(questionItem);
  });
}

function selectOption(element, questionId, selectedOption, correctAnswer) {
  // Remove any existing highlighting
  const options = element.parentElement.querySelectorAll('.option');
  options.forEach(opt => {
    opt.classList.remove('correct', 'incorrect');
  });
  
  // Highlight selected option
  if (selectedOption === correctAnswer) {
    element.classList.add('correct');
  } else {
    element.classList.add('incorrect');
    // Also show correct answer
    const correctElement = element.parentElement.querySelector(`.option[data-option="${correctAnswer}"]`);
    if (correctElement) {
      correctElement.classList.add('correct');
    }
  }
}

function filterQuestions(category) {
  // Update filter buttons
  document.querySelectorAll('.filter-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
  
  generateQuestionBank(category);
}

function toggleAnswer(questionId) {
  const answerDiv = document.getElementById(`answer-${questionId}`);
  const button = answerDiv.previousElementSibling;
  
  if (answerDiv.style.display === 'block') {
    answerDiv.style.display = 'none';
    button.textContent = 'Show Answer & Explanation';
  } else {
    answerDiv.style.display = 'block';
    button.textContent = 'Hide Answer';
    // Update progress
    updateProgress();
  }
}

function markQuestionSolved(questionId) {
  let progress = JSON.parse(localStorage.getItem('nlp-progress') || '{}');
  if (!progress.solvedQuestions) progress.solvedQuestions = [];
  if (!progress.solvedQuestions.includes(questionId)) {
    progress.solvedQuestions.push(questionId);
    localStorage.setItem('nlp-progress', JSON.stringify(progress));
    updateProgress();
    alert('Question marked as solved!');
  }
}

// TEXT PROCESSING FUNCTIONS
let currentTool = 'tokenize';

function selectTool(tool) {
  document.querySelectorAll('.tool-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
  
  currentTool = tool;
  updateToolDescription();
}

function updateToolDescription() {
  const descriptions = {
    'tokenize': 'Split text into individual tokens (words, punctuation).',
    'pos': 'Identify parts of speech for each token (Noun, Verb, Adjective, etc.).',
    'ner': 'Extract named entities like persons, organizations, locations.',
    'sentiment': 'Analyze the emotional tone (positive, negative, neutral).',
    'dependency': 'Parse grammatical structure and relationships between words.',
    'summarize': 'Generate a concise summary of the input text.',
    'translate': 'Translate text between different languages.',
    'embedding': 'Convert words to vector representations.'
  };
  
  // Update UI with current tool description
  document.querySelector('.process-btn').innerHTML = `<i class="fas fa-play"></i> ${currentTool.charAt(0).toUpperCase() + currentTool.slice(1)} Text`;
}

function processText() {
  const inputText = document.getElementById('input-text').value;
  const resultsPanel = document.getElementById('results-panel');
  
  if (!inputText.trim()) {
    resultsPanel.innerHTML = '<div class="result-item"><strong>Please enter some text to process.</strong></div>';
    return;
  }
  
  // Simulate processing results based on selected tool
  let results = '';
  
  switch(currentTool) {
    case 'tokenize':
      const tokens = inputText.split(/\s+/);
      results = `<div class="result-item">
                  <strong>Tokens (${tokens.length}):</strong>
                  <div class="token-container">
                    ${tokens.map(token => `<span class="token">${token}</span>`).join('')}
                  </div>
                </div>`;
      break;
      
    case 'pos':
      // Simulate POS tagging
      const sampleTokens = ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'fascinating', '.'];
      const samplePOS = ['ADJ', 'NOUN', 'NOUN', 'PUNCT', 'PROPN', 'PUNCT', 'VERB', 'ADJ', 'PUNCT'];
      results = `<div class="result-item">
                  <strong>POS Tags:</strong>
                  <div class="token-container">
                    ${sampleTokens.map((token, i) => 
                      `<span class="token pos-${samplePOS[i]}">${token} (${samplePOS[i]})</span>`
                    ).join('')}
                  </div>
                </div>`;
      break;
      
    case 'ner':
      results = `<div class="result-item">
                  <strong>Named Entities:</strong>
                  <div class="result-item">
                    <span style="background: rgba(81,207,102,0.2); padding: 3px 8px; border-radius: 4px; margin-right: 5px;">Google (ORG)</span>
                    <span style="background: rgba(81,207,102,0.2); padding: 3px 8px; border-radius: 4px; margin-right: 5px;">Microsoft (ORG)</span>
                    <span style="background: rgba(81,207,102,0.2); padding: 3px 8px; border-radius: 4px; margin-right: 5px;">OpenAI (ORG)</span>
                    <span style="background: rgba(74,158,255,0.2); padding: 3px 8px; border-radius: 4px; margin-right: 5px;">BERT (MISC)</span>
                    <span style="background: rgba(74,158,255,0.2); padding: 3px 8px; border-radius: 4px; margin-right: 5px;">GPT-3 (MISC)</span>
                    <span style="background: rgba(74,158,255,0.2); padding: 3px 8px; border-radius: 4px;">ChatGPT (MISC)</span>
                  </div>
                </div>`;
      break;
      
    case 'sentiment':
      const sentimentScore = Math.random() > 0.5 ? 0.85 : -0.42;
      const sentimentLabel = sentimentScore > 0 ? 'Positive' : sentimentScore < 0 ? 'Negative' : 'Neutral';
      const sentimentColor = sentimentScore > 0 ? '#51cf66' : sentimentScore < 0 ? '#ff4757' : '#ffcc00';
      
      results = `<div class="result-item">
                  <strong>Sentiment Analysis:</strong>
                  <div class="result-item">
                    <strong>Label:</strong> <span style="color: ${sentimentColor};">${sentimentLabel}</span><br>
                    <strong>Score:</strong> ${sentimentScore.toFixed(2)} (range: -1 to 1)<br>
                    <strong>Confidence:</strong> ${(Math.abs(sentimentScore) * 100).toFixed(1)}%
                  </div>
                </div>`;
      break;
      
    case 'dependency':
      results = `<div class="result-item">
                  <strong>Dependency Parse (Simplified):</strong>
                  <div class="code-block">
root(ROOT-0, is-7)<br>
nsubj(is-7, Processing-3)<br>
compound(Processing-3, Natural-1)<br>
compound(Processing-3, Language-2)<br>
appos(Processing-3, NLP-5)<br>
punct(NLP-5, (-4)<br>
punct(NLP-5, )-6)<br>
acomp(is-7, fascinating-8)<br>
punct(is-7, .-9)
                  </div>
                </div>`;
      break;
      
    case 'summarize':
      results = `<div class="result-item">
                  <strong>Summary:</strong>
                  <div class="result-item" style="background: rgba(159,122,234,0.1); padding: 15px; border-radius: 8px;">
                    NLP is an AI field that enables computers to process human language. Modern techniques like transformers have revolutionized text processing, with models like BERT and GPT performing tasks like translation and summarization accurately.
                  </div>
                </div>`;
      break;
      
    case 'translate':
      results = `<div class="result-item">
                  <strong>Translation (Spanish):</strong>
                  <div class="result-item" style="background: rgba(255,169,77,0.1); padding: 15px; border-radius: 8px;">
                    El Procesamiento del Lenguaje Natural (PLN) es un campo fascinante de la inteligencia artificial que permite a las computadoras entender, interpretar y generar lenguaje humano. Técnicas modernas de PLN, como los transformadores y mecanismos de atención, han revolucionado cómo las máquinas procesan texto.
                  </div>
                </div>`;
      break;
      
    case 'embedding':
      results = `<div class="result-item">
                  <strong>Word Embeddings (sample vectors):</strong>
                  <div class="code-block">
"Natural": [0.24, -0.12, 0.56, ..., 0.89]<br>
"Language": [0.67, 0.45, -0.23, ..., 0.12]<br>
"Processing": [0.89, -0.56, 0.34, ..., -0.45]<br>
"artificial": [0.45, 0.78, -0.12, ..., 0.67]<br>
"intelligence": [0.78, 0.12, 0.45, ..., -0.23]<br>
<br>
<strong>Cosine Similarities:</strong><br>
Natural-Language: 0.85<br>
artificial-intelligence: 0.92<br>
Processing-intelligence: 0.67
                  </div>
                </div>`;
      break;
  }
  
  resultsPanel.innerHTML = results;
  
  // Update progress
  let progress = JSON.parse(localStorage.getItem('nlp-progress') || '{}');
  progress.textProcessed = (progress.textProcessed || 0) + 1;
  localStorage.setItem('nlp-progress', JSON.stringify(progress));
  updateProgress();
}

function loadTemplate(type) {
  const templates = {
    'news': `Scientists at MIT have developed a new AI model that can predict protein structures with unprecedented accuracy. The breakthrough could accelerate drug discovery and lead to new treatments for diseases like Alzheimer's and cancer. The model, called AlphaFold 3.0, outperforms all previous methods and is now available to researchers worldwide.`,
    
    'review': `I recently purchased the XYZ wireless headphones and I'm extremely disappointed with the quality. The sound is tinny, the battery life is much shorter than advertised, and they frequently disconnect from my devices. For the price, I expected much better. Would not recommend.`,
    
    'scientific': `The transformer architecture, first introduced in the paper "Attention Is All You Need", revolutionized natural language processing. It employs a self-attention mechanism that allows it to weigh the importance of different words in a sequence, enabling parallel computation and improved handling of long-range dependencies compared to recurrent neural networks.`,
    
    'social': `Just finished watching the new sci-fi movie on Netflix! The visual effects were stunning and the plot kept me on the edge of my seat. Highly recommend to all sci-fi fans! #Netflix #SciFi #MovieReview`,
    
    'code': `# This function calculates the cosine similarity between two vectors
def cosine_similarity(vec1, vec2):
    """
    Calculate cosine similarity between two vectors.
    
    Parameters:
    vec1 (np.array): First vector
    vec2 (np.array): Second vector
    
    Returns:
    float: Cosine similarity score
    """
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)`
  };
  
  if (templates[type]) {
    document.getElementById('input-text').value = templates[type];
  }
}

// MODEL PLAYGROUND FUNCTIONS
let currentModel = 'rnn';

function selectModel(model) {
  document.querySelectorAll('.tool-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
  
  currentModel = model;
  updateModelInfo();
}

function updateModelInfo() {
  const modelInfo = {
    'rnn': {params: '1.2M', loss: '2.34', val: '2.45', acc: '78.5%'},
    'lstm': {params: '2.8M', loss: '1.89', val: '2.01', acc: '82.3%'},
    'transformer': {params: '15.6M', loss: '1.45', val: '1.52', acc: '88.7%'},
    'bert': {params: '110M', loss: '1.12', val: '1.18', acc: '92.4%'},
    'gpt': {params: '345M', loss: '0.98', val: '1.05', acc: '94.2%'}
  };
  
  const info = modelInfo[currentModel];
  document.getElementById('current-model').textContent = currentModel.toUpperCase();
  document.getElementById('model-params').textContent = info.params;
  document.getElementById('train-loss').textContent = info.loss;
  document.getElementById('val-loss').textContent = info.val;
  document.getElementById('model-accuracy').textContent = info.acc;
}

function trainModel() {
  // Simulate training
  document.getElementById('train-time').textContent = `${Math.floor(Math.random() * 60) + 30}s`;
  
  // Update progress
  let progress = JSON.parse(localStorage.getItem('nlp-progress') || '{}');
  progress.modelsTrained = (progress.modelsTrained || 0) + 1;
  localStorage.setItem('nlp-progress', JSON.stringify(progress));
  updateProgress();
  
  alert(`Training ${currentModel.toUpperCase()} model...\n\nIn a real implementation, this would train the model with your selected parameters.`);
}

function generateText() {
  const prompts = [
    "The future of artificial intelligence",
    "Natural language processing has revolutionized",
    "In a world where machines can understand",
    "The key challenge in building chatbots is",
    "Transformers have become the dominant architecture"
  ];
  
  const completions = [
    " will be shaped by advances in multimodal learning and reasoning capabilities.",
    " how we interact with technology, making human-computer communication more natural than ever before.",
    " human language, the possibilities for innovation are endless across education, healthcare, and entertainment.",
    " maintaining coherent context over extended conversations while providing helpful and accurate responses.",
    " for NLP tasks due to their ability to handle long-range dependencies and parallel computation."
  ];
  
  const prompt = prompts[Math.floor(Math.random() * prompts.length)];
  const completion = completions[Math.floor(Math.random() * completions.length)];
  
  document.getElementById('model-output').value = prompt + completion;
}

// DATASET EXPLORER FUNCTIONS
function loadDataset(dataset) {
  // Update active button
  document.querySelectorAll('.tool-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
  
  // Update dataset info
  const datasetInfo = {
    'imdb': {
      name: 'IMDB Reviews',
      description: '50,000 movie reviews labeled as positive or negative for sentiment analysis.',
      size: '50K samples',
      task: 'Binary Classification'
    },
    'squad': {
      name: 'SQuAD',
      description: 'Stanford Question Answering Dataset - reading comprehension dataset with questions on Wikipedia articles.',
      size: '100K+ Q-A pairs',
      task: 'Question Answering'
    },
    'glue': {
      name: 'GLUE',
      description: 'General Language Understanding Evaluation benchmark for evaluating NLP models across multiple tasks.',
      size: '9 tasks',
      task: 'Multi-task Evaluation'
    },
    'wiki': {
      name: 'Wikipedia',
      description: 'Clean extracts from Wikipedia articles for pretraining language models.',
      size: '2.5B tokens',
      task: 'Pretraining'
    },
    'news': {
      name: 'News Articles',
      description: 'Collection of news articles from various sources for text classification and summarization.',
      size: '500K articles',
      task: 'Multi-class Classification'
    },
    'twitter': {
      name: 'Twitter Sentiment',
      description: 'Tweets labeled with sentiment (positive, negative, neutral) for sentiment analysis.',
      size: '1.6M tweets',
      task: 'Sentiment Analysis'
    },
    'reddit': {
      name: 'Reddit Comments',
      description: 'Large corpus of Reddit comments for language modeling and conversation analysis.',
      size: '1.7B comments',
      task: 'Language Modeling'
    }
  };
  
  const info = datasetInfo[dataset];
  document.getElementById('dataset-info').innerHTML = `
    <p><strong>${info.name}</strong></p>
    <p>${info.description}</p>
    <p><strong>Size:</strong> ${info.size}</p>
    <p><strong>Task:</strong> ${info.task}</p>
  `;
  
  // Generate sample data
  generateSampleData(dataset);
  
  // Update progress
  let progress = JSON.parse(localStorage.getItem('nlp-progress') || '{}');
  progress.datasetsExplored = (progress.datasetsExplored || 0) + 1;
  localStorage.setItem('nlp-progress', JSON.stringify(progress));
  updateProgress();
}

function generateSampleData(dataset) {
  const tbody = document.getElementById('dataset-body');
  tbody.innerHTML = '';
  
  const samples = {
    'imdb': [
      {text: "This movie was absolutely fantastic! The acting was superb and the plot kept me engaged from start to finish.", label: "positive", length: 15, sentiment: "positive"},
      {text: "Terrible waste of time. Poor direction, awful acting, and a predictable plot that went nowhere.", label: "negative", length: 12, sentiment: "negative"},
      {text: "A decent film with some good moments, but ultimately forgettable. Not bad, but not great either.", label: "positive", length: 14, sentiment: "neutral"},
      {text: "One of the best films I've seen this year! The cinematography was stunning and the score was perfect.", label: "positive", length: 16, sentiment: "positive"},
      {text: "I really wanted to like this movie, but it was just boring. The characters were flat and uninteresting.", label: "negative", length: 13, sentiment: "negative"}
    ],
    'squad': [
      {text: "What is the capital of France?", label: "Paris", length: 6, sentiment: "N/A"},
      {text: "When was the Declaration of Independence signed?", label: "1776", length: 7, sentiment: "N/A"},
      {text: "Who wrote 'Pride and Prejudice'?", label: "Jane Austen", length: 6, sentiment: "N/A"},
      {text: "What is the largest planet in our solar system?", label: "Jupiter", length: 9, sentiment: "N/A"},
      {text: "How many elements are in the periodic table?", label: "118", length: 8, sentiment: "N/A"}
    ],
    'twitter': [
      {text: "Just had the best coffee ever! #coffeelover", label: "positive", length: 7, sentiment: "positive"},
      {text: "Stuck in traffic for 2 hours. This is ridiculous! #traffic", label: "negative", length: 9, sentiment: "negative"},
      {text: "Excited for the new product launch tomorrow! #tech", label: "positive", length: 8, sentiment: "positive"},
      {text: "The weather today is absolutely perfect. #sunny", label: "positive", length: 6, sentiment: "positive"},
      {text: "Customer service was terrible. Never buying from them again.", label: "negative", length: 10, sentiment: "negative"}
    ]
  };
  
  const data = samples[dataset] || samples['imdb'];
  
  data.forEach(sample => {
    const row = document.createElement('tr');
    row.innerHTML = `
      <td style="max-width: 300px; word-wrap: break-word;">${sample.text}</td>
      <td>${sample.label}</td>
      <td>${sample.length}</td>
      <td>${sample.sentiment}</td>
    `;
    tbody.appendChild(row);
  });
  
  document.getElementById('data-count').textContent = data.length;
  document.getElementById('total-count').textContent = dataset === 'imdb' ? '50,000' : 
                                                      dataset === 'squad' ? '100,000+' : 
                                                      dataset === 'twitter' ? '1,600,000' : '500,000';
}

function loadMoreData() {
  alert('Loading more data...\n\nIn a real implementation, this would fetch additional samples from the selected dataset.');
}

// PROGRESS TRACKING
function updateProgress() {
  let progress = JSON.parse(localStorage.getItem('nlp-progress') || '{}');
  
  // Initialize if needed
  if (!progress.solvedQuestions) progress.solvedQuestions = [];
  if (!progress.textProcessed) progress.textProcessed = 0;
  if (!progress.modelsTrained) progress.modelsTrained = 0;
  if (!progress.datasetsExplored) progress.datasetsExplored = 0;
  
  // Count concepts viewed (simplified)
  const conceptsViewed = document.querySelectorAll('.concept-card.learned').length;
  
  // Calculate overall progress
  const overallProgress = Math.min(100,
    (conceptsViewed / 8) * 25 +
    (progress.solvedQuestions.length / 10) * 25 +
    (progress.modelsTrained / 5) * 25 +
    (progress.datasetsExplored / 5) * 25
  );
  
  // Save progress
  localStorage.setItem('nlp-progress', JSON.stringify(progress));
  
  // Update UI
  document.getElementById('concepts-mastered').textContent = conceptsViewed;
  document.getElementById('questions-solved').textContent = progress.solvedQuestions.length;
  document.getElementById('models-trained').textContent = progress.modelsTrained;
  document.getElementById('datasets-explored').textContent = progress.datasetsExplored;
  document.getElementById('overall-progress').textContent = Math.round(overallProgress) + '%';
  document.getElementById('overall-progress-bar').style.width = overallProgress + '%';
  
  // Update recommendations
  const recommendations = document.getElementById('recommendations');
  if (conceptsViewed < 4) {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--warning);"></i> <strong>Recommendation:</strong> Study at least 4 fundamental NLP concepts from the Fundamentals section.</p>';
  } else if (progress.solvedQuestions.length < 5) {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--warning);"></i> <strong>Recommendation:</strong> Solve at least 5 questions from the Question Bank to test your understanding.</p>';
  } else if (progress.modelsTrained < 2) {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--warning);"></i> <strong>Recommendation:</strong> Experiment with different model architectures in the Model Playground.</p>';
  } else if (progress.datasetsExplored < 2) {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--warning);"></i> <strong>Recommendation:</strong> Explore different NLP datasets in the Dataset Explorer.</p>';
  } else if (overallProgress < 50) {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--nlp-blue);"></i> <strong>Recommendation:</strong> Focus on attention mechanisms and transformer architectures.</p>';
  } else {
    recommendations.innerHTML = '<p><i class="fas fa-lightbulb" style="color: var(--nlp-green);"></i> <strong>Great progress!</strong> Try building a complete NLP project or contribute to open-source NLP libraries.</p>';
  }
}

function resetProgress() {
  if (confirm("Are you sure you want to reset all progress?")) {
    localStorage.removeItem('nlp-progress');
    document.querySelectorAll('.concept-card').forEach(card => {
      card.classList.remove('learned');
    });
    updateProgress();
  }
}

// Initialize everything
document.addEventListener('DOMContentLoaded', function() {
  // Initialize question bank
  generateQuestionBank('all');
  
  // Initialize text processing
  updateToolDescription();
  
  // Initialize model playground
  updateModelInfo();
  
  // Initialize progress with demo data
  if (!localStorage.getItem('nlp-progress')) {
    const demoProgress = {
      solvedQuestions: [1, 2, 3, 6, 7],
      textProcessed: 3,
      modelsTrained: 1,
      datasetsExplored: 2
    };
    localStorage.setItem('nlp-progress', JSON.stringify(demoProgress));
  }
  
  updateProgress();
  
  // Add concept learning tracking
  document.querySelectorAll('.concept-card').forEach((card, index) => {
    card.addEventListener('click', function() {
      if (!this.classList.contains('learned')) {
        this.classList.add('learned');
        updateProgress();
      }
    });
  });
  
  // Render KaTeX formulas
  document.querySelectorAll('.formula-content').forEach(element => {
    try {
      katex.render(element.textContent, element, {
        throwOnError: false
      });
    } catch (e) {
      console.log('KaTeX rendering error:', e);
    }
  });
  
  // Initialize dataset explorer
  loadDataset('imdb');
});
</script>
</body>
</html>